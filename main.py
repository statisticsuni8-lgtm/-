import os
import time
import random
import requests
import threading
from datetime import datetime, timedelta, timezone
from flask import Flask
from apscheduler.schedulers.background import BackgroundScheduler

# ==========================================
# [ì„¤ì •] í™˜ê²½ ë³€ìˆ˜ & ëª¨ë¸
# ==========================================
# Railwayì—ì„œ NOUS_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìˆ˜
API_KEY = os.getenv("NOUS_API_KEY") 
API_URL = "https://inference-api.nousresearch.com/v1/chat/completions"
# Railwayê°€ í• ë‹¹í•´ì£¼ëŠ” í¬íŠ¸ (ê¸°ë³¸ 8080)
PORT = int(os.environ.get("PORT", 8080)) 

MODELS = {
    "PRIMARY": "Hermes-3-Llama-3.1-405B", 
    "SECONDARY": "Hermes-3-Llama-3.1-70B"
}

app = Flask(__name__)
# ìƒíƒœ ì €ì¥ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
last_run_status = {"time": "Never", "mode": "None", "status": "Initializing"}

# ==========================================
# [ë°ì´í„° ì—”ì§„] ì£¼ì œ: AI ê¸°ìˆ  ë° ì—ì´ì „íŠ¸ ê°œë°œ
# ==========================================
def gen_tech_trend_data():
    """Mode A: ìµœì‹  AI ê¸°ìˆ  ë™í–¥ ë°ì´í„°"""
    techs = ["Multi-modal RAG", "Autonomous Agents", "Small Language Models", "AI Governance"]
    focus = random.choice(techs)
    return f"TOPIC: {focus}\nTREND_SCORE: {random.randint(70, 100)}\nRESEARCH_LAB: {random.choice(['DeepMind','OpenAI','Meta','Anthropic'])}", "TECH_ANALYSIS"

def gen_coding_challenge():
    """Mode B: ì—ì´ì „íŠ¸ ë¡œì§ êµ¬í˜„ ì‹œë‚˜ë¦¬ì˜¤"""
    tasks = ["Tool Calling Logic", "Memory Management", "Self-Reflection Loop"]
    return f"AGENT_TASK: {random.choice(tasks)}\nLANGUAGE: Python\nERROR_LOG: Memory leak in long-term context buffer.", "AGENT_DEV"

def gen_short_qa():
    """Mode C: ì§§ì€ ê¸°ìˆ  ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸"""
    questions = ["What is the difference between LoRA and QLoRA?", "Explain Chain-of-Thought prompting.", "Best practices for API security?"]
    return random.choice(questions), "QUICK_QA"

# ==========================================
# [ìš”ì²­ ì²˜ë¦¬ê¸°]
# ==========================================
def execute_api(payload, model_name):
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    try:
        resp = requests.post(API_URL, headers=headers, json=payload, timeout=120)
        if resp.status_code == 200:
            usage = resp.json().get('usage', {})
            print(f"      âœ… Success ({model_name}): In={usage.get('prompt_tokens')} Out={usage.get('completion_tokens')}")
            return resp.json()['choices'][0]['message']['content']
        else:
            print(f"      âš ï¸ Error {resp.status_code}")
            return None
    except Exception as e:
        print(f"      âš ï¸ Exception: {e}")
        return None

def process_request(model, prompt, max_t, temp):
    payload = {"model": model, "messages": [{"role": "user", "content": prompt}], "max_tokens": max_t, "temperature": temp}
    return execute_api(payload, model)

def process_request_history(model, messages, max_t):
    payload = {"model": model, "messages": messages, "max_tokens": max_t, "temperature": 0.8}
    return execute_api(payload, model)

# ==========================================
# [í–‰ë™ íŒ¨í„´]
# ==========================================
def run_deep_analysis():
    print(" >>> [Mode: Deep Analysis] Deep dive into AI Trends...")
    data, theme = gen_tech_trend_data()
    prompt = f"Data:\n{data}\n\n[TASK]: Write a professional 1000-word research summary about this trend's impact on 2026."
    process_request(MODELS["PRIMARY"], prompt, 1200, 0.7)
    return "Deep Analysis"

def run_dev_sprint():
    print(" >>> [Mode: Dev Sprint] Solving Agent logic...")
    data, theme = gen_coding_challenge()
    messages = [
        {"role": "system", "content": "You are a senior AI Engineer."},
        {"role": "user", "content": f"Fix this agent issue:\n{data}"}
    ]
    process_request_history(MODELS["PRIMARY"], messages, 800)
    return "Dev Sprint"

def run_rapid_check():
    print(" >>> [Mode: Rapid Check] Quick tech Q&A...")
    data, theme = gen_short_qa()
    process_request(MODELS["SECONDARY"], data, 300, 0.5)
    return "Rapid Check"

# ==========================================
# [ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œì§]
# ==========================================
def get_korea_time():
    return datetime.now(timezone.utc) + timedelta(hours=9)

def job_logic():
    global last_run_status
    
    # API í‚¤ í™•ì¸
    if not API_KEY: 
        print("âŒ Error: NOUS_API_KEY not found in environment variables.")
        last_run_status["status"] = "Error: No API Key"
        return

    hour = get_korea_time().hour
    current_time_str = get_korea_time().strftime('%Y-%m-%d %H:%M:%S')

    # ìˆ˜ë©´ ëª¨ë“œ (03ì‹œ~08ì‹œ KST)
    if 3 <= hour < 8:
        print(f"[{current_time_str}] ğŸ’¤ Sleep mode active.")
        last_run_status = {"time": current_time_str, "mode": "Sleep", "status": "Sleeping..."}
        return

    # ì‹¤í–‰ ëª¨ë“œ ê²°ì •
    dice = random.random()
    mode_name = ""
    try:
        if dice < 0.4: 
            mode_name = run_deep_analysis()
        elif dice < 0.8: 
            mode_name = run_dev_sprint()
        else: 
            mode_name = run_rapid_check()
        
        last_run_status = {"time": current_time_str, "mode": mode_name, "status": "Success"}
    except Exception as e:
        print(f"âŒ Error during job execution: {e}")
        last_run_status = {"time": current_time_str, "mode": "Error", "status": str(e)}

# ==========================================
# [Railway Health Check ì—”ë“œí¬ì¸íŠ¸]
# ==========================================
@app.route('/')
def health_check():
    """ì›¹ ë¸Œë¼ìš°ì €ë¡œ ì ‘ì† ì‹œ ë´‡ ìƒíƒœ í‘œì‹œ"""
    html = f"""
    <html>
        <head>
            <title>AI Agent Status</title>
            <meta http-equiv="refresh" content="60"> </head>
        <body style="font-family: sans-serif; padding: 40px; line-height: 1.6;">
            <h1>ğŸ¤– AI Agent Status Board</h1>
            <div style="background: #f4f4f4; padding: 20px; border-radius: 10px;">
                <p><strong>ğŸ•’ Current KST:</strong> {get_korea_time().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p><strong>âœ… Last Execution:</strong> {last_run_status['time']}</p>
                <p><strong>ğŸ› ï¸ Last Mode:</strong> {last_run_status['mode']}</p>
                <p><strong>ğŸ“¡ Status:</strong> <span style="color: {'green' if last_run_status['status'] == 'Success' else 'red'}">{last_run_status['status']}</span></p>
            </div>
            <p style="color: gray; margin-top: 20px;">* Running on Railway. Scheduling interval: 12-25 mins.</p>
        </body>
    </html>
    """
    return html

if __name__ == "__main__":
    print("=== AI Agent Started ===")
    
    # 1. ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    scheduler = BackgroundScheduler()
    # 12ë¶„ ~ 25ë¶„ ì‚¬ì´ ëœë¤ ê°„ê²©ìœ¼ë¡œ ì‹¤í–‰
    scheduler.add_job(job_logic, 'interval', minutes=random.randint(12, 25))
    scheduler.start()

    # 2. ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ì¦‰ì‹œ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ìš©)
    print("ğŸš€ Triggering initial test run...")
    threading.Thread(target=job_logic).start()

    # 3. Flask ì›¹ ì„œë²„ ì‹¤í–‰ (Railway í¬íŠ¸ ë°”ì¸ë”©)
    print(f"ğŸŒ Starting Web Server on port {PORT}")
    app.run(host='0.0.0.0', port=PORT)
